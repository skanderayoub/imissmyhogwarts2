{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import webbrowser\n",
    "from urllib.parse import urljoin, unquote\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Step 1: Send an HTTP request to the webpage\n",
    "url = 'https://archive.org/download/hogwarts-legacy-voice-files'  # Replace with the URL you want to scrape\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract string between /download/ and .rar/\n",
    "def extract_string_between(text, start, end):\n",
    "    start_index = text.find(start) + len(start)\n",
    "    end_index = text.find(end, start_index)\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "# Step 3: Find all <a> tags containing the text \"View content\"\n",
    "folders = []\n",
    "for a_tag in soup.find_all('a', string=\"View Contents\"):\n",
    "    href = a_tag.get('href')\n",
    "    if href:\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        full_url = urljoin(url, href)\n",
    "        extracted_string = extract_string_between(full_url, '/download/', '.rar/')\n",
    "        folders.append(extracted_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://ia601601.us.archive.org/view_archive.php?archive=/29/items/hogwarts-legacy-voice-files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseUrl(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save links json file\n",
    "# Create a dictionary\n",
    "data = {}\n",
    "for folder in folders:\n",
    "    data[unquote(folder)] = []\n",
    "    final_link = url2 + folder + \".rar\"\n",
    "    soup = parseUrl(final_link)\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        href = a_tag.get('href')\n",
    "        if href:\n",
    "            # Convert relative URLs to absolute URLs\n",
    "            urls = urljoin(url, href)\n",
    "            if urls.endswith(\".wav\"):\n",
    "                data[unquote(folder)].append(urls)  \n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('links.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urls = [\n",
    "    \"https://downloads.khinsider.com/game-soundtracks/album/hogwarts-legacy-study-themes-from-the-original-video-game-soundtrack-2023\",\n",
    "    \"https://downloads.khinsider.com/game-soundtracks/album/hogwarts-legacy-original-video-game-soundtrack-2023\"\n",
    "]\n",
    "data = {}\n",
    "for url in urls:\n",
    "    soup = parseUrl(url)\n",
    "    title = soup.find(\"h2\").text\n",
    "    files = []\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        href = a_tag.get('href')\n",
    "        if href:\n",
    "            # Convert relative URLs to absolute URLs\n",
    "            full_url = urljoin(url, href)\n",
    "            if full_url.endswith('.mp3'):\n",
    "                files.append(full_url)\n",
    "    files = list(set(files))\n",
    "    srcs = []\n",
    "    for file in files:\n",
    "        soup = parseUrl(file)\n",
    "        for tag in soup.find_all(\"audio\"):\n",
    "            src = tag.get(\"src\")\n",
    "            srcs.append(src)\n",
    "    data[title] = srcs\n",
    "\n",
    "with open('music.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk in folder ./assets\n",
    "wallpapers = []\n",
    "for path, dir, files in os.walk('./assets'):\n",
    "    for file in files:\n",
    "        # check if file ends with .jpg, .jpeg or .png\n",
    "        if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n",
    "            wallpapers.append(path + '/' + file)\n",
    "\n",
    "with open('wallpapers.json', 'w') as f:\n",
    "    json.dump(wallpapers, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
